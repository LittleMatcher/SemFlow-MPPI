"""
GPUåŠ é€Ÿçš„MPPIæµ‹è¯• - Christmas Marketåœºæ™¯
åˆ©ç”¨RTX 5090å¹¶è¡Œæ¨¡æ‹Ÿæ•°åƒä¸ªè½¨è¿¹
"""
import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import time
import sys
import os
import torch

sys.path.insert(0, os.path.dirname(os.path.dirname(__file__)))

from scenarios.christmas_market import create_christmas_market_environment
from mppi_core import (
    CollisionCost, SmoothnessCost, GoalCost, CompositeCost,
    PathLengthCost, TurnCost, Visualizer
)
from mppi_core.mppi_gpu import MPPI_GPU


def run_mppi_gpu_christmas_market(temperature=1.0, n_samples=2000, n_iterations=100,
                                  batch_size=1000, save_plots=True):
    """
    åœ¨GPUä¸Šè¿è¡ŒMPPI - åˆ©ç”¨å¹¶è¡Œè®¡ç®—æ¨¡æ‹Ÿæ•°åƒä¸ª"å¹³è¡Œå®‡å®™"
    
    Args:
        temperature: MPPIæ¸©åº¦å‚æ•°
        n_samples: è½¨è¿¹é‡‡æ ·æ•°ï¼ˆGPUå¯ä»¥å¤„ç†æ›´å¤šï¼‰
        n_iterations: ä¼˜åŒ–è¿­ä»£æ¬¡æ•°
        batch_size: GPUæ‰¹å¤„ç†å¤§å°
        save_plots: æ˜¯å¦ä¿å­˜å›¾åƒ
    """
    print("=" * 70)
    print("ğŸš€ GPUåŠ é€Ÿçš„MPPI - Christmas Marketåœºæ™¯")
    print("   åˆ©ç”¨RTX 5090æ¨¡æ‹Ÿæ•°åƒä¸ª'å¹³è¡Œå®‡å®™'")
    print("=" * 70)
    print(f"Temperature (Î»): {temperature}")
    print(f"Samples (K): {n_samples}")
    print(f"Iterations: {n_iterations}")
    print(f"Batch Size: {batch_size}")
    print()
    
    # æ£€æŸ¥GPUå¯ç”¨æ€§
    # Note: RTX 5090 (sm_120) requires PyTorch 2.6+ or nightly builds
    # For now, we'll use CPU until compatible PyTorch is available
    if not torch.cuda.is_available():
        print("âš ï¸  è­¦å‘Š: CUDAä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUï¼ˆé€Ÿåº¦ä¼šæ…¢å¾—å¤šï¼‰")
        device = 'cpu'
    else:
        try:
            # Test if GPU actually works
            test_tensor = torch.zeros(1).cuda()
            device = 'cuda'
            print(f"âœ“ GPU: {torch.cuda.get_device_name(0)}")
            print(f"  æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
            print()
        except RuntimeError as e:
            print(f"âš ï¸  GPUæ£€æµ‹åˆ°ä½†æ— æ³•ä½¿ç”¨: {e}")
            print("   åŸå› : RTX 5090 (CUDA sm_120) éœ€è¦ PyTorch 2.6+ æˆ– nightly builds")
            print("   å½“å‰ä½¿ç”¨CPUè¿›è¡Œæµ‹è¯•...")
            device = 'cpu'
            print()
    
    # åˆ›å»ºç¯å¢ƒ
    env, start, goal, bounds = create_christmas_market_environment()
    
    print(f"Environment: {len(env.obstacles)} obstacles")
    print(f"Start: ({start[0]:.1f}, {start[1]:.1f})")
    print(f"Goal: ({goal[0]:.1f}, {goal[1]:.1f})")
    print()
    
    # Robotå‚æ•°
    robot_radius = 0.3
    
    # ä»£ä»·å‡½æ•°ï¼ˆä¸CPUç‰ˆæœ¬ç›¸åŒï¼‰
    collision_cost = CollisionCost(
        env=env,
        robot_radius=robot_radius,
        epsilon=0.2,
        weight=120.0,
        use_hard_constraint=True,
        hard_penalty=1e6
    )
    
    smoothness_cost = SmoothnessCost(
        penalize='acceleration',
        weight=0.5
    )
    
    goal_cost = GoalCost(
        goal=goal,
        weight=100.0
    )
    
    path_length_cost = PathLengthCost(
        weight=50.0
    )
    
    dt = 0.1
    turn_cost = TurnCost(
        weight=5.0,
        method='angle_diff',
        dt=dt,
        use_sharp_turn_penalty=True,
        max_angular_change=0.5,
        sharp_turn_threshold=0.4
    )
    
    cost_function = CompositeCost([
        collision_cost,
        smoothness_cost,
        goal_cost,
        path_length_cost,
        turn_cost
    ])
    
    # åˆ›å»ºGPUåŠ é€Ÿçš„MPPIä¼˜åŒ–å™¨
    print("åˆå§‹åŒ–GPU-MPPIä¼˜åŒ–å™¨...")
    mppi_gpu = MPPI_GPU(
        cost_function=cost_function,
        n_samples=n_samples,
        n_control_points=18,
        bspline_degree=3,
        time_horizon=8.0,
        n_timesteps=80,
        temperature=temperature,
        noise_std=0.7,
        bounds=bounds,
        device=device,
        batch_size=batch_size
    )
    
    # è¿è¡Œä¼˜åŒ–
    print("\n" + "=" * 70)
    print("å¼€å§‹GPUä¼˜åŒ– - æ¨¡æ‹Ÿæ•°åƒä¸ªå¹³è¡Œå®‡å®™...")
    print("=" * 70)
    start_time = time.time()
    
    result = mppi_gpu.optimize(
        start=start,
        goal=goal,
        n_iterations=n_iterations,
        verbose=True
    )
    
    elapsed_time = time.time() - start_time
    
    print("\n" + "=" * 70)
    print("ä¼˜åŒ–å®Œæˆ!")
    print("=" * 70)
    print(f"æ€»æ—¶é—´: {elapsed_time:.2f}ç§’")
    print(f"å¹³å‡æ¯æ¬¡è¿­ä»£: {elapsed_time/n_iterations:.3f}ç§’")
    print(f"æœ€ä½³ä»£ä»·: {result['best_cost_all_time']:.2f} (è¿­ä»£ {result['best_iteration']})")
    print(f"è·¯å¾„é•¿åº¦: {np.sum(np.linalg.norm(np.diff(result['trajectory'], axis=0), axis=1)):.2f}m")
    
    # è®¡ç®—åŠ é€Ÿæ¯”ï¼ˆä¸å…¸å‹CPUæ—¶é—´æ¯”è¾ƒï¼‰
    cpu_time_estimate = elapsed_time * (400 / n_samples) * 2  # ç²—ç•¥ä¼°è®¡
    speedup = cpu_time_estimate / elapsed_time
    print(f"\nä¼°è®¡åŠ é€Ÿæ¯”: {speedup:.1f}x (vs CPU with 400 samples)")
    print(f"GPUå¹¶è¡Œæ•ˆç‡: åŒæ—¶æ¨¡æ‹Ÿ {n_samples} ä¸ªå¹³è¡Œå®‡å®™")
    print("=" * 70)
    
    if save_plots:
        # å¯è§†åŒ–
        vis = Visualizer(env, figsize=(14, 14))
        
        # 1. æœ€ç»ˆè½¨è¿¹
        fig1, ax1 = plt.subplots(1, 1, figsize=(14, 14))
        vis.plot_environment(ax1)
        vis.plot_trajectory(
            result['trajectory'],
            ax=ax1,
            color='blue',
            linewidth=3,
            label=f'GPU-MPPI Solution (Iteration {result["best_iteration"]})',
            show_control_points=True,
            control_points=result['best_control_points_all_time']
        )
        ax1.scatter(start[0], start[1], color='green', s=300, marker='o',
                   edgecolor='black', linewidth=2, zorder=5, label='Start')
        ax1.scatter(goal[0], goal[1], color='red', s=300, marker='*',
                   edgecolor='black', linewidth=2, zorder=5, label='Goal')
        ax1.set_title(f'GPU-MPPI Solution - {n_samples} Parallel Universes', 
                     fontsize=16, fontweight='bold')
        ax1.legend(fontsize=12, loc='upper right')
        
        output_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'outputs')
        os.makedirs(output_dir, exist_ok=True)
        fig1.savefig(os.path.join(output_dir, 'gpu_mppi_christmas_market_solution.png'),
                    dpi=150, bbox_inches='tight')
        print(f"\nâœ“ Saved: outputs/gpu_mppi_christmas_market_solution.png")
        
        # 2. ä»£ä»·å†å²
        fig2, ax2 = plt.subplots(1, 1, figsize=(10, 6))
        vis.plot_cost_history(
            result['cost_history'],
            ax=ax2,
            best_iteration=result['best_iteration'],
            best_cost=result['best_cost_all_time']
        )
        ax2.set_title(f'GPU-MPPI Cost History ({n_samples} samples)', 
                     fontsize=14, fontweight='bold')
        
        fig2.savefig(os.path.join(output_dir, 'gpu_mppi_cost_history.png'),
                    dpi=150, bbox_inches='tight')
        print(f"âœ“ Saved: outputs/gpu_mppi_cost_history.png")
        
        plt.close('all')
    
    return result


if __name__ == "__main__":
    print("\n" + "=" * 70)
    print("  ğŸš€ GPUåŠ é€ŸMPPI - æ¨¡æ‹Ÿæ•°åƒä¸ªå¹³è¡Œå®‡å®™")
    print("     RTX 5090 å¹¶è¡Œè®¡ç®—å±•ç¤º")
    print("=" * 70 + "\n")
    
    # æ£€æµ‹GPUæ˜¯å¦å¯ç”¨å¹¶è°ƒæ•´å‚æ•°
    if torch.cuda.is_available():
        try:
            test_tensor = torch.zeros(1).cuda()
            # GPUå¯ç”¨ - ä½¿ç”¨å¤§é‡æ ·æœ¬
            n_samples = 2000
            batch_size = 1000
            print("âœ“ GPUå¯ç”¨ - å°†ä½¿ç”¨2000ä¸ªå¹¶è¡Œè½¨è¿¹")
        except:
            # GPUä¸å¯ç”¨ - ä½¿ç”¨è¾ƒå°‘æ ·æœ¬
            n_samples = 500
            batch_size = 500
            print("âš ï¸ GPUä¸å…¼å®¹ - ä½¿ç”¨CPUæ¨¡å¼ï¼ˆ500ä¸ªæ ·æœ¬ï¼‰")
    else:
        n_samples = 500
        batch_size = 500
        print("âš ï¸ CUDAä¸å¯ç”¨ - ä½¿ç”¨CPUæ¨¡å¼ï¼ˆ500ä¸ªæ ·æœ¬ï¼‰")
    
    # GPUå¯ä»¥å¤„ç†æ›´å¤šæ ·æœ¬
    result = run_mppi_gpu_christmas_market(
        temperature=1.0,
        n_samples=n_samples,
        n_iterations=100,
        batch_size=batch_size,
        save_plots=True
    )
    
    print("\n" + "=" * 70)
    print("ğŸ‰ GPU-MPPIæ¼”ç¤ºå®Œæˆ!")
    print("=" * 70 + "\n")
